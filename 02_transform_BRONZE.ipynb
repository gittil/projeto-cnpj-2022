{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as Func \n",
    "from pyspark.sql.functions import *\n",
    "import modules \n",
    "from modules import my_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").\\\n",
    "    appName(\"CNPJ_bronze\").\\\n",
    "        config(\"spark.executer.memory\",\"1gb\").\\\n",
    "            getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/douglas/DATA/PRJ_CNPJ/new_data/ETL/02.Bronze/*.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\")\\\n",
    "    .option(\"delimiter\",\";\")\\\n",
    "        .option(\"enconding\",\"ISO-8859-1\")\\\n",
    "            .option(\"header\",\"False\")\\\n",
    "                .option(\"inferSchema\",\"True\")\\\n",
    "                    .load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos a função converterColuna para converter o tipo da coluna, no caso as datas estavam como strings pois foi inferido de forma automática\n",
    "# Na variável colunas_time informamos quais serão as colunas que irão passam pela mudança de tipo\n",
    "colunas_time = ['dt_cad','dt_inicio_at']\n",
    "my_func.converterColuna(df,colunas_time,DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Após as colunas de data receberem o tipo correto temos que formatar as datas. \n",
    "df = df_select.withColumn(\"dt_sit_cad\", to_date(df_select.dt_cad,'yyyyMMdd'))\n",
    "df = df.withColumn(\"dt_ini_atv\", to_date(df_select.dt_inicio_at,'yyyyMMdd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo as datas no formato antigo e no novo formato\n",
    "df.select(['dt_cad','dt_sit_cad','dt_inicio_at','dt_ini_atv']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos dropar as  colunas antigas pois não precisamos mais delas\n",
    "df = df.drop('dt_cad','dt_inicio_at')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71046af2f65c12de5be553af3af49a03a0746b5ef2338e39a62aea16fa296259"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
